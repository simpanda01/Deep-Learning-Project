{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "11lHktGyIAXOjPw0CMTv5f77wnr0ExVIZ",
      "authorship_tag": "ABX9TyM/j2HAgLiRq8gbxOZFdC1Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritika2024/Lumpy-Skin-Diseases-using-deep-learning/blob/main/FEATURE_EXTRACTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0-LCUpxWCME",
        "outputId": "b03be760-c1e2-4e4d-d83e-e5daf70cd158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "w6jusu8SD-Ir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60b47c45-b3c4-47cc-f60c-3a750af28978"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0BdU79Ffs1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ss_62ehVXRX",
        "outputId": "c0464046-0074-45e6-95ab-f611d54197e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 600 files [00:12, 48.14 files/s]\n"
          ]
        }
      ],
      "source": [
        "import splitfolders # or import splitfolders\n",
        "input_folder = \"/content/drive/MyDrive/AUGMENTED NEW/AUGMENTED\"\n",
        "output = \"/content/drive/MyDrive/OUTPUT NEW \" #where you want the split datasets saved. one will be created if it does not exist or none is set\n",
        "\n",
        "splitfolders.ratio(input_folder, output=output, seed=42, ratio=(.80, .0, .20))  #train val test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np ;\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Reshape,Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "import itertools\n",
        "import cv2\n",
        "import pandas as pd ;\n",
        "import matplotlib.pyplot as plt ;\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16 , ResNet50 , Xception , InceptionV3, DenseNet121, MobileNet\n",
        "from tensorflow.keras.layers import Flatten\n",
        "import pandas as pd\n",
        "import os\n",
        "\n"
      ],
      "metadata": {
        "id": "JW867oM8XVzS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Uncomment this if want to use\n",
        "\n",
        "#model1 = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "model2 = ResNet50(weights='imagenet', include_top=False );\n",
        "\n",
        "#model3 = Xception(weights='imagenet', include_top=False );\n",
        "\n",
        "#model4 = InceptionV3(weights='imagenet', include_top=False );\n",
        "\n",
        "# Add a flatten layer on top of VGG16\n",
        "flatten_layer = Flatten()\n",
        "model2 = tf.keras.Sequential([model2, flatten_layer])\n",
        "\n",
        "# Load the dataset and extract features\n",
        "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    #\"../Covid19-dataset/test/\",\n",
        "    \"/content/drive/MyDrive/OUTPUT NEW /train\"\n",
        "    ,batch_size=500,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=False,\n",
        "    color_mode=\"rgb\")\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "for batch, label in dataset:\n",
        "    batch_features = model2.predict(batch)\n",
        "    features.append(batch_features)\n",
        "    labels.append(label.numpy())\n",
        "    #print(label)\n",
        "\n",
        "files0=dataset.file_paths\n",
        "files=[]\n",
        "for file in files0:\n",
        "     files.append(os.path.basename(file))\n",
        "\n",
        "\n",
        "\n",
        "# Combine features and labels into a feature-label dataset\n",
        "features = tf.concat(features, axis=0)\n",
        "labels = tf.concat(labels, axis=0)\n",
        "print(\"Features Shape:\", features.shape)\n",
        "print(\"Labels Shape:\", labels.shape)\n",
        "\n",
        "files= pd.DataFrame(files)\n",
        "labels= pd.DataFrame(labels)\n",
        "features = pd.DataFrame(features)\n",
        "#labels=labels.insert(loc = len(labels.columns),column='1',value = files)\n",
        "\n",
        "features = pd.concat([labels, files, features], axis=1)\n",
        "features = features[:].values\n",
        "features=pd.DataFrame(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbybdrXIgcqS",
        "outputId": "ef4c8d68-c51d-4162-837c-e2e85564359c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 480 files belonging to 2 classes.\n",
            "15/15 [==============================] - 85s 6s/step\n",
            "Features Shape: (480, 100352)\n",
            "Labels Shape: (480,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "qZ22Twb1gLDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df= pd.DataFrame(features)\n",
        "df= features\n",
        "df.to_csv('/content/drive/MyDrive/AUGMENTED NEW/RESNET50.csv', index=False)"
      ],
      "metadata": {
        "id": "gH9dSOU-Yby6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}