{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19Q4lXHfD6XLgAw2lCVLqPJja8zzFYwzU",
      "authorship_tag": "ABX9TyMiGdtiLkiVnMIVorNPSVII",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ritika2024/Lumpy-Skin-Diseases-using-deep-learning/blob/main/PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "w6jusu8SD-Ir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36b47b96-30e9-47e5-cbcf-e1cae9d365c0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "87csnjZ2RT6W"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path= '/content/drive/MyDrive/AUGMENTED NEW/outputresnetvgg.csv'"
      ],
      "metadata": {
        "id": "w85Kty2NRZqP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MIN MAX Scaling function\n",
        "def min_max_scale(X):\n",
        " from sklearn.preprocessing import MinMaxScaler\n",
        " scaler = MinMaxScaler()\n",
        " X = scaler.fit_transform(X)\n",
        " return X"
      ],
      "metadata": {
        "id": "rRa-SogvRjb4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for Principal component analysis\n",
        "#95% of variance\n",
        "def pca_analysis(X):\n",
        " from sklearn.decomposition import PCA\n",
        " pca = PCA(n_components = 0.95)\n",
        " pca.fit(X)\n",
        " X = pca.transform(X)\n",
        " return X\n"
      ],
      "metadata": {
        "id": "X3W_lTqsRnpf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunksize = 750\n",
        "tfr = pd.read_csv(path, chunksize=chunksize, iterator=True,header= None)\n",
        "X_array =[]\n",
        "Y_array= []\n",
        "Y_DF= pd.DataFrame(Y_array)\n",
        "X_DF = pd.DataFrame(X_array)\n",
        "X_DF\n",
        "i=1\n",
        "with tfr as reader:\n",
        "    for chunk in reader:\n",
        "        print(\"index_value\")\n",
        "        print(i)\n",
        "        X = chunk.iloc[:,1:]\n",
        "        X = min_max_scale(X)\n",
        "        X = pca_analysis(X)\n",
        "        X = pd.DataFrame(X)\n",
        "        X_DF = pd.concat([X_DF,X], axis=0, ignore_index=True)\n",
        "        Y = chunk.iloc[:, 0]\n",
        "        Y_DF = pd.concat([Y_DF,Y], axis=0, ignore_index=True)\n",
        "        i=i+1\n",
        ""
      ],
      "metadata": {
        "id": "zzb2nDGw7rUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_DF"
      ],
      "metadata": {
        "id": "y9-gDpin8Cj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing extra NAN values with 0\n",
        "X_DF = X_DF.fillna(0)\n",
        "\n",
        "#Joining X and Y\n",
        "X= X_DF.to_numpy()\n",
        "Y= Y_DF.to_numpy()\n",
        "X = np.hstack((Y,X))\n",
        "df= pd.DataFrame(X)\n",
        "\n",
        "\n",
        "#Converting first column to int\n",
        "#and leaving every other column to float\n",
        "firstCol = list(df.columns)[0]\n",
        "df[firstCol] = df[firstCol].astype(int)\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "wuAsm5G78QFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving dataframe to csv\n",
        "\n",
        "df.to_csv(\"/content/drive/MyDrive/AUGMENTED NEW/pcaoutput.csv\", index=False, header=False)"
      ],
      "metadata": {
        "id": "QJ-OUb0z8hSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "RFJaj1Nl8nr7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}